{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Disable logging of the program in the notebook\n",
    "os.environ[\"LOGLEVEL\"] = \"CRITICAL\"\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(os.environ.get(\"LOGLEVEL\", logging.FATAL))\n",
    "\n",
    "pybooklogger = logging.getLogger('pybook')\n",
    "pybooklogger.setLevel(logging.DEBUG)\n",
    "\n",
    "%aimport generation\n",
    "\n",
    "from old_generation import generate\n",
    "from parseRePEAT import *"
   ],
   "id": "5e7bd9538e3d790b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Plotting for the arrival time function\n",
    "Top plot is the arrival time set out over the departure time\n",
    "\n",
    "Bottom plot is the sum of the delay of the agents\n"
   ],
   "id": "5853ba5470de5171"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_atf(segments, axs, eatfs, **kwargs):\n",
    "    color = kwargs.get('color', None)\n",
    "    label = kwargs.get('label', None)\n",
    "    y_offset = kwargs.get('y_offset', 0)\n",
    "\n",
    "    if 'expected_arrival_time' in kwargs:\n",
    "        eat = kwargs['expected_arrival_time']\n",
    "        axs[0].axhline(eat)\n",
    "\n",
    "    line = None\n",
    "    for (x0, x1, y0, y1) in segments:\n",
    "        if x0 == \"-inf\" and x1 != \"inf\" and y1 != \"inf\":\n",
    "            axs[0].hlines(float(y1) + y_offset, 0, float(x1), colors=color)\n",
    "        line, = axs[0].plot([float(x0), float(x1)], [float(y0) + y_offset, float(y1) + y_offset], color=color)\n",
    "    line.set_label(label) if line is not None else None\n",
    "\n",
    "    plotted_intervals = []\n",
    "    for path_eatf in eatfs.values():\n",
    "        for (zeta, alpha, beta, delta, gammas) in path_eatf:\n",
    "            min_gamma = 0\n",
    "            max_gamma = 0\n",
    "            for gamma_min, gamma_max, rt in gammas:\n",
    "                # if gamma_max > gamma_min:\n",
    "                #     raise ValueError(f\"Max gamma > Min gamma, {gamma_max} > {gamma_min}\")\n",
    "                min_gamma += max(float(gamma_min) - float(rt), 0)\n",
    "                max_gamma += max(float(gamma_max) - float(rt), 0)\n",
    "\n",
    "            alpha = float(alpha)\n",
    "            beta = float(beta)\n",
    "\n",
    "            plotted_intervals.append((min(alpha, beta), beta, min_gamma, max_gamma))\n",
    "\n",
    "            if alpha <= beta:\n",
    "                # axs[1].plot([previous_beta, alpha], [min_gamma + y_offset, min_gamma + y_offset], color=color)\n",
    "                axs[1].plot([alpha, beta], [min_gamma + y_offset, max_gamma + y_offset], color=color)\n",
    "            # else:\n",
    "            #     # axs[1].plot([previous_beta, beta - (gamma_diff)], [min_gamma + y_offset, min_gamma + y_offset], color=color)\n",
    "            #     axs[1].plot([beta - (gamma_diff), beta], [min_gamma + y_offset, max_gamma + y_offset], color=color)\n",
    "            # axs[1].plot([float(alpha), float(beta)], [min_gammas, max_gammas], color=color)\n",
    "            previous_beta = beta\n",
    "\n",
    "    previous_beta = 0\n",
    "    plotted_intervals.sort(key=lambda x: x[0])\n",
    "\n",
    "    for (alpha, beta, min_gamma, max_gamma) in plotted_intervals:\n",
    "        axs[1].plot([previous_beta, alpha], [min_gamma + y_offset, min_gamma + y_offset], color=color)\n",
    "        previous_beta = beta\n",
    "\n",
    "            # pybooklogger.info(f\"{alpha}, {beta}, {gammas}, {min_gammas} - {max_gammas}\")"
   ],
   "id": "3b01545eec6ca5de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def setup_plt(**kwargs):\n",
    "    widths = [10]\n",
    "    heights = [4, 1]\n",
    "    fig, axs = plt.subplots(ncols=1, nrows=2, gridspec_kw={\"height_ratios\": heights, \"width_ratios\": widths})\n",
    "    axs = axs.transpose()\n",
    "    fig.set_figheight(7)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    axs[0].set_xlabel(\"Departure time (hh:mm:ss)\")\n",
    "    axs[1].set_xlabel(\"Departure time (hh:mm:ss)\")\n",
    "    axs[0].set_ylabel(\"Arrival time (hh:mm:ss)\")\n",
    "    axs[1].set_ylabel(\"Total delay of agents (s)\")\n",
    "    axs[0].set_title(\"Arrival Time Function\")\n",
    "    axs[0].set_xlim(left=kwargs.get(\"min_x\", None), right=kwargs.get(\"max_x\", None))\n",
    "    axs[1].set_xlim(left=kwargs.get(\"min_x\", None), right=kwargs.get(\"max_x\", None))\n",
    "    axs[0].set_ylim(bottom=kwargs.get(\"min_y\", None), top=kwargs.get(\"max_y\", None))\n",
    "    axs[0].grid()\n",
    "    axs[1].grid()\n",
    "\n",
    "    axs[0].set_xticklabels([str(timedelta(seconds=xtick)) for xtick in axs[0].get_xticks()])\n",
    "    axs[0].set_yticklabels([str(timedelta(seconds=ytick)) for ytick in axs[0].get_yticks()])\n",
    "    axs[1].set_xticklabels([str(timedelta(seconds=xtick)) for xtick in axs[1].get_xticks()])\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "def plot_experiments(exps, save_path=None, **kwargs):\n",
    "    fig, axs = setup_plt(**kwargs)\n",
    "    for e in exps:\n",
    "        if e.results is None:\n",
    "            pybooklogger.info(f\"No results found, skipping {e}\")\n",
    "            continue\n",
    "        pybooklogger.info(f\"Plotting {e}\")\n",
    "        e.plot(axs, **kwargs)\n",
    "\n",
    "    axs[0].legend()\n",
    "    if save_path:\n",
    "        fig.savefig(f\"figures/{save_path}\")\n",
    "    plt.show()"
   ],
   "id": "6f936af848c2cf1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classes to setup for the experiment\n",
    "\n",
    "## Agent\n",
    "Represents a train, where the id is -1 for planning a new train, or the index of a train, starting at 1, of a train that is trying to replan in the scenarios file"
   ],
   "id": "c972b6ad4dcc97af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Agent:\n",
    "    def __init__(self, id, origin, destination, velocity, start_time, **kwargs):\n",
    "        self.id = id\n",
    "        self.origin = origin\n",
    "        self.destination = destination\n",
    "        self.velocity = velocity\n",
    "        self.start_time = start_time\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)"
   ],
   "id": "f054221e90cd3e7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Layout\n",
    "holds to track layout and generates the track graph and route graph"
   ],
   "id": "3dc89ef809e58eda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Layout:\n",
    "    def __init__(self, layout):\n",
    "        self.g, self.g_block, self.g_duration, self.g_block_duration = generate.time_graph_creation(layout)\n",
    "\n",
    "    def station_to_block(self, station, direction=0):\n",
    "        if station + \"a\" in self.g_block.stations:\n",
    "            station = station + \"a\"\n",
    "        if station in self.g_block.stations:\n",
    "            if direction == \"A\":\n",
    "                direction = 0\n",
    "            if direction == \"B\":\n",
    "                direction = 1\n",
    "            return self.g_block.stations[station][direction]\n",
    "        pybooklogger.error(f\"Station {station} not found\")\n",
    "        return station\n",
    "\n",
    "    def get_path_for_agent(self, move, current_train, velocity):\n",
    "        from generation.interval_generation import construct_path\n",
    "        from generation.signal_sections import convertMovesToBlock\n",
    "\n",
    "        path = construct_path(self.g, move, current_agent=current_train, agent_velocity=velocity)\n",
    "        moves_per_agent = {current_train: [path]}\n",
    "        return convertMovesToBlock(moves_per_agent, self.g, current_train)"
   ],
   "id": "57933c9eba6a66c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenario\n",
    "Holds the unsafe intervals for every agent in the scenario file"
   ],
   "id": "6cefaa8a3f04ff3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Scenario:\n",
    "    def __init__(self, l: Layout, scen_file, agent_id):\n",
    "        self.l = l\n",
    "        self.agent_id = agent_id\n",
    "        self.block_intervals, self.moves_per_agent, self.unsafe_computation_time, self.block_routes, self.t_moves_to_block = generate.time_scenario_creation(scen_file, self.l.g, self.l.g_block, agent_id)\n",
    "\n",
    "    def get_flexibility(self, max_buffer_time, use_recovery_time):\n",
    "        return generate.time_flexibility_creation(self.block_routes, self.block_intervals, max_buffer_time, use_recovery_time)\n",
    "\n",
    "    def plot(self, agent_to_plot_route_of, buffer_times, recovery_times, plot_route_of_agent_to_plot_route_of=True):\n",
    "        exclude_agent=-1\n",
    "        if not plot_route_of_agent_to_plot_route_of:\n",
    "            exclude_agent=agent_to_plot_route_of\n",
    "        generate.plot_route(agent_to_plot_route_of, self.moves_per_agent, self.block_routes, self.block_intervals, self.l.g_block, buffer_times, recovery_times, exclude_agent=exclude_agent)"
   ],
   "id": "b99eeacf1a0d204d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment\n",
    "Calculates the safe intervals given the max buffer time and recovery time.\n",
    "\n",
    "Also can call the FlexSIPP search in C++."
   ],
   "id": "801832bdd21403f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Experiment:\n",
    "    def __init__(self, s: Scenario, agent: Agent, max_buffer_time, use_recovery_time, metadata):\n",
    "        self.s = s\n",
    "        self.agent = agent\n",
    "        self.metadata= metadata\n",
    "\n",
    "        self.buffer_times, self.recovery_times, self.time_flexibility_creation = s.get_flexibility(max_buffer_time, use_recovery_time)\n",
    "        self.safe_block_intervals, self.safe_block_edges_intervals, self.atfs, self.indices_to_states, self.safe_computation_time = generate.time_interval_creation(self.s.block_intervals, self.s.l.g_block, self.buffer_times, self.recovery_times, self.agent.destination, agent.velocity)\n",
    "        self.results = None\n",
    "\n",
    "    def run_search(self, timeout):\n",
    "        file = \"output\"\n",
    "        generate.write_intervals_to_file(file, self.safe_block_intervals, self.atfs, self.indices_to_states)\n",
    "        try:\n",
    "            proc = subprocess.run([\"../search/buildDir/atsipp.exe\", \"--start\", self.agent.origin, \"--goal\", self.agent.destination, \"--edgegraph\", file, \"--search\", \"repeat\", \"--startTime\", str(self.agent.start_time)], timeout=timeout, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "\n",
    "        except subprocess.TimeoutExpired:\n",
    "            pybooklogger.error(f'Timeout for repeat ({timeout}s) expired')\n",
    "            return\n",
    "        if int(proc.returncode) == 0:\n",
    "            repeat_output = str(proc.stdout).split(\"'\")[1].rsplit(\"\\\\r\\\\n\")\n",
    "            pybooklogger.debug(f\"repeat output: {repeat_output}\")\n",
    "            metadata, catf, paths, eatfs = parse_list_of_outputs(repeat_output)\n",
    "            pybooklogger.info(f\"eats: {eatfs}\")\n",
    "            pybooklogger.info(f\"cats: {catf}\")\n",
    "            self.results = (metadata, catf, paths, eatfs)\n",
    "\n",
    "\n",
    "    def plot(self, axs, **kwargs):\n",
    "        plot_atf(self.results[1], axs, self.results[3], label=self.metadata[\"label\"], color=self.metadata[\"color\"], y_offset=self.metadata[\"offset\"], **kwargs)\n",
    "\n",
    "    def get_running_time(self):\n",
    "        return {\n",
    "            \"unsafe interval generation\": self.s.unsafe_computation_time,\n",
    "            \"safe interval generation\": self.safe_computation_time,\n",
    "            \"bt and crt generation\": self.time_flexibility_creation,\n",
    "            \"converting routes to blocks\": self.s.t_moves_to_block,\n",
    "            \"track graph creation\": self.s.l.g_duration,\n",
    "            \"routing graph creation\": self.s.l.g_block_duration,\n",
    "            \"FlexSIPP search time\": float(self.results[0][\"Search time\"]) / 1000.0,\n",
    "            \"Lookup time\": float(self.results[0][\"Lookup time\"]) / 1000.0,\n",
    "        }\n",
    "\n",
    "    def get_complexity(self):\n",
    "        return {\n",
    "            \"nodes generated\": int(self.results[0][\"Nodes generated\"]),\n",
    "            \"nodes decreased\": int(self.results[0][\"Nodes decreased\"]),\n",
    "            \"nodes expanded\": int(self.results[0][\"Nodes expanded\"]),\n",
    "        }"
   ],
   "id": "dbadecbe23ff97e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_experiments(exps: list[Experiment], timeout):\n",
    "    for e in exps:\n",
    "        e.run_search(timeout)"
   ],
   "id": "4c28e45d53ef30ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment setup\n",
    "Create a list of experiments that can be run from the settings"
   ],
   "id": "d0506c7b84e090d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def setup_experiment(scenario: Scenario, overwrite_settings):\n",
    "    experiments = []\n",
    "    for exp in overwrite_settings:\n",
    "        set_default(exp)\n",
    "        origin = exp[\"origin\"]\n",
    "        destination = exp[\"destination\"]\n",
    "        velocity = exp[\"velocity\"]\n",
    "        start_time = exp[\"start_time\"]\n",
    "        max_buffer_time = exp[\"max_buffer_time\"]\n",
    "        use_recovery_time = exp[\"use_recovery_time\"]\n",
    "        metadata = exp[\"metadata\"]\n",
    "\n",
    "        agent_id = scenario.agent_id\n",
    "        pybooklogger.info(f\"Setting up experiment {exp}\")\n",
    "\n",
    "        origin_signal = scenario.l.station_to_block(origin)\n",
    "        destination_signal = scenario.l.station_to_block(destination)\n",
    "        agent = Agent(agent_id, origin_signal, destination_signal, velocity, start_time)\n",
    "\n",
    "\n",
    "        experiments.append(Experiment(scenario, agent, max_buffer_time, use_recovery_time, metadata))\n",
    "    return experiments"
   ],
   "id": "51ecf51d19cfcc52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Default settings\n",
    "Default settings for when not everything is specified"
   ],
   "id": "1118be63b67a066a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "default_settings = {\n",
    "    \"origin\": \"ASD|13a\",\n",
    "    \"destination\": \"RTD|2\",\n",
    "    \"velocity\": 140/3.6,\n",
    "    \"max_buffer_time\": 0,\n",
    "    \"start_time\": 0,\n",
    "    \"use_recovery_time\": False,\n",
    "    \"metadata\": {\n",
    "        \"color\": \"Red\",\n",
    "        \"label\": \"No flexibility\",\n",
    "        \"offset\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "def _set_default(setting: dict, default: dict):\n",
    "    for key, value in default.items():\n",
    "        if key not in setting:\n",
    "            setting[key] = value\n",
    "        elif isinstance(value, dict):\n",
    "            _set_default(setting[key], value)\n",
    "\n",
    "def set_default(setting):\n",
    "    _set_default(setting, default_settings)"
   ],
   "id": "1009fdb622eba25f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Track Layout\n",
    "Calculate the layout of the dutch railway system\n"
   ],
   "id": "b2c022e90c686bde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "layout_file =   \"../data/prorail/parsed/netherlands-schiphol.json\"\n",
    "layout = Layout(layout_file)"
   ],
   "id": "1c7c0298ab22324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edges_df = pd.DataFrame({\"Outgoing routes\": [len(n.outgoing) for n in layout.g_block.nodes.values() if len(n.outgoing) <= 25]})\n",
    "hist = edges_df.hist(bins=25, )\n",
    "plt.xlabel(\"Number of outgoing routes\")\n",
    "plt.ylabel(\"Number of occurrences\")\n",
    "plt.show()"
   ],
   "id": "6ce55ea528c9a462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agents",
   "id": "bbf89ab5223712cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario_file = \"../data/prorail/scenarios/SHL-2025-06-30.json\"\n",
    "try:\n",
    "    base_path = Path(__file__).parent\n",
    "    file_path = (base_path / scenario_file).resolve()\n",
    "    data = json.load(open(file_path))\n",
    "except:\n",
    "    data = json.load(open(scenario_file))\n",
    "types = {x[\"name\"]: x for x in data[\"types\"]}\n",
    "agents = []\n",
    "for trainNumber, entry in enumerate(data[\"trains\"]):\n",
    "    trainNumber += 1\n",
    "    move = entry[\"movements\"][0]\n",
    "    velocity = types[entry[\"trainUnitTypes\"][0]][\"speed\"] / 3.6\n",
    "\n",
    "    block_path = layout.get_path_for_agent(move, trainNumber, velocity)\n",
    "\n",
    "    agent = Agent(trainNumber, move[\"startLocation\"], move[\"endLocation\"], velocity, move[\"startTime\"],\n",
    "                  endTime=move[\"endTime\"],\n",
    "                  startTimeHuman=str(timedelta(seconds=move[\"startTime\"])),\n",
    "                  endTimeHuman=str(timedelta(seconds=move[\"endTime\"])),\n",
    "                  blockPath=block_path,\n",
    "                  trainNumber=entry[\"trainNumber\"],\n",
    "                  trainUnitTypes=entry[\"trainUnitTypes\"],\n",
    "                  stops=move[\"stops\"]\n",
    "    )\n",
    "    agents.append(agent)\n",
    "\n",
    "agent_df = pd.DataFrame([agent.__dict__ for agent in agents])\n",
    "agent_df['blockPathLength'] = agent_df['blockPath'].map(len)\n",
    "\n",
    "print(f\"total blocks in path: {agent_df['blockPathLength'].sum()}\")\n",
    "print(f\"total edges in graph: {edges_df['Outgoing routes'].sum()}\")\n",
    "\n",
    "agent_df"
   ],
   "id": "58784899abb750bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiment Shl -> Rtd\n",
    "\n",
    "Second experiment as described in the thesis, where we plan in an extra train from Schiphol to Rotterdam, not going over the HSL line but through Leiden and The Hague."
   ],
   "id": "dc8fdd1a431480d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Scenario\n",
    "First load the scenario where we don't include agent 1 (used for plotting the path) that is the Eurostar train."
   ],
   "id": "6c2c0d86f9c30f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario_file = \"../data/prorail/scenarios/SHL-2025-06-30.json\"\n",
    "# Replan these agents, -1 is planning in a new agent\n",
    "agent_id = 1\n",
    "scenario = Scenario(layout, scenario_file, agent_id)"
   ],
   "id": "fa8c08b149ad473d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment\n",
    "Define three experiments:\n",
    "1. Classical @SIPP, no extra flexibility\n",
    "2. FlexSIPP but not including the recovery time\n",
    "3. FlexSIPP"
   ],
   "id": "65ddd2241466c694"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup experiment\n",
    "experiment_settings = [\n",
    "    {\n",
    "        \"start_time\": 1080,\n",
    "        \"origin\": \"SHL|6\",\n",
    "        \"destination\": \"RTD|2\",\n",
    "        \"metadata\": {\n",
    "            \"offset\": 2,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"start_time\": 1080,\n",
    "        \"max_buffer_time\": 500,\n",
    "        \"origin\": \"SHL|6\",\n",
    "        \"destination\": \"RTD|2\",\n",
    "        \"metadata\": {\n",
    "            \"color\": \"Green\",\n",
    "            \"label\": \"Buffer time\",\n",
    "            \"offset\": 1,\n",
    "        }\n",
    "    },{\n",
    "        \"start_time\": 1080,\n",
    "        \"origin\": \"SHL|6\",\n",
    "        \"destination\": \"RTD|2\",\n",
    "        \"max_buffer_time\": 500,\n",
    "        \"use_recovery_time\": True,\n",
    "        \"metadata\": {\n",
    "            \"color\": \"Blue\",\n",
    "            \"label\": \"Recovery time\",\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "experiments = setup_experiment(scenario, experiment_settings)"
   ],
   "id": "e14872413bd724ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Blocking staircase diagram\n",
    "Showing the route of Shl -> Rtd"
   ],
   "id": "743747faeab8fcbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    exp.s.plot(1, exp.buffer_times, exp.recovery_times, False)"
   ],
   "id": "8aad1060ee0c1996",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timeout = 600\n",
    "run_experiments(experiments, timeout)"
   ],
   "id": "5836d62dc5bf9214",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "### ATF Plot"
   ],
   "id": "52bb45d41ecd6ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pybooklogger.setLevel(logging.WARNING)\n",
    "experiments[0].metadata = {'color': 'Red', 'label': 'No flexibility', 'offset': 15}\n",
    "experiments[1].metadata = {'color': 'Green', 'label': 'Buffer time', 'offset': 0}\n",
    "experiments[2].metadata = {'color': 'Blue', 'label': 'Recovery time', 'offset': -15}\n",
    "experiments[0].results[1][1] = ('1672.78', '2750.88', '5377.17', '5377.17')\n",
    "\n",
    "kwargs = {\"min_x\": 1080, \"max_x\": 3000, \"min_y\": 2500, \"max_y\": 7000}\n",
    "plot_experiments(experiments, **kwargs)\n",
    "\n",
    "\n",
    "experiments[0].metadata = {'color': 'Red', 'label': 'No flexibility', 'offset': 0}\n",
    "experiments[1].metadata = {'color': 'Green', 'label': 'Buffer time', 'offset': 0}\n",
    "experiments[2].metadata = {'color': 'Blue', 'label': 'Recovery time', 'offset': 0}\n",
    "\n",
    "plot_experiments([experiments[0]], **kwargs)\n",
    "plot_experiments([experiments[1]], **kwargs)\n",
    "plot_experiments([experiments[2]], **kwargs)"
   ],
   "id": "696edb41caaf098b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time statistics",
   "id": "7e1ee30181198a7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sum_cols(df1, cols, name):\n",
    "    df2 = df1.drop(columns=cols)\n",
    "    df2[name] = df1[cols].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "time_df = pd.DataFrame([exp.get_running_time() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "setup_cols = [\"track graph creation\", \"routing graph creation\"]\n",
    "recompute_cols = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\"]\n",
    "search_cols = [\"FlexSIPP search time\"]\n",
    "\n",
    "time_df = sum_cols(time_df, setup_cols, \"Setup Time\")\n",
    "time_df = sum_cols(time_df, recompute_cols, \"Recompute Time\")\n",
    "time_df = sum_cols(time_df, search_cols, \"Search Time\")\n",
    "\n",
    "print(time_df.to_latex())"
   ],
   "id": "2e4d25221c42355d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Node Statistics",
   "id": "dd6ee8978e3131a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nodes_df = pd.DataFrame([exp.get_complexity() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "print(nodes_df.to_latex())"
   ],
   "id": "45a12d91c2b34401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output paths found",
   "id": "3d40ea4ee1881dee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key, value in experiments[2].results[3].items():\n",
    "    delayed_trains = {i: v for i,v in enumerate(value[0][4]) if float(v[0]) > 0}\n",
    "    print(f\"{key.replace('r-', '')}\\nearliest departure: {int(min(float(value[0][1]), float(value[0][2])) / 60)}\\ndepart before: {int(float(value[0][2]) / 60)}\\narrive at: {int((float(value[0][1]) + float(value[0][3])) / 60)}\\ndelays trains: {delayed_trains}\")"
   ],
   "id": "c745b8090e8aaef6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path statistics",
   "id": "91ff2ea2cf5ae4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    print(f\"Differend paths found for {exp.metadata['label']}: {sum(exp.results[2].values())}\")"
   ],
   "id": "dc3dd99c322293f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiment Gvc -> Shl and further\n",
    "\n",
    "Experiment to test the validity against a TAD"
   ],
   "id": "d1d72a7ac3b1a69e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenario\n",
    "\n",
    "Replan agents of the series 3500o"
   ],
   "id": "24ecd9d5e16da544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario_file = \"../data/prorail/scenarios/SHL-2025-06-30-TAD.json\"\n",
    "series_3500o = agent_df.loc[(agent_df['trainNumber'].str.startswith(\"35\", na=False)) & (agent_df['trainNumber'].astype(int) % 2 == 1)]\n",
    "\n",
    "# This train would be at 2700 at GV|6, we will be replanning its path till ASDZ|2\n",
    "agent = series_3500o.iloc[1]\n",
    "series_3500o"
   ],
   "id": "db15b6fa37672c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replan these agents, -1 is planning in a new agent\n",
    "agent_id = agent['id']\n",
    "scenario = Scenario(layout, scenario_file, agent_id)"
   ],
   "id": "b33eeacb7c37f75d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment\n",
    "Define\n",
    "three\n",
    "experiments:\n",
    "1.\n",
    "Classical @ SIPP, no\n",
    "extra\n",
    "flexibility\n",
    "2.\n",
    "FlexSIPP\n",
    "but\n",
    "not including\n",
    "the\n",
    "recovery\n",
    "time\n",
    "3.\n",
    "FlexSIPP\n",
    "\n"
   ],
   "id": "7da5576b2102d091"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup experiment\n",
    "experiment_settings = [\n",
    "    {\n",
    "        \"start_time\": 2700.0,\n",
    "        \"origin\": \"GV|6\",\n",
    "        \"destination\": \"ASDZ|2\",\n",
    "        \"metadata\": {\n",
    "            \"offset\": 2,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"start_time\": 2700.0,\n",
    "        \"origin\": \"GV|6\",\n",
    "        \"destination\": \"ASDZ|2\",\n",
    "        \"max_buffer_time\": 900,\n",
    "        \"metadata\": {\n",
    "            \"color\": \"Green\",\n",
    "            \"label\": \"Buffer time\",\n",
    "            \"offset\": 1,\n",
    "        }\n",
    "    }, {\n",
    "        \"start_time\": 2700.0,\n",
    "        \"origin\": \"GV|6\",\n",
    "        \"destination\": \"ASDZ|2\",\n",
    "        \"max_buffer_time\": 900,\n",
    "        \"use_recovery_time\": True,\n",
    "        \"metadata\": {\n",
    "            \"color\": \"Blue\",\n",
    "            \"label\": \"Recovery time\",\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "experiments = setup_experiment(scenario, experiment_settings)"
   ],
   "id": "e955005497df2050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Blocking staircase diagram\n",
    "Showing the route of GV -> ASDZ|2 and more even, TODO"
   ],
   "id": "f7e0898fed02525e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    exp.s.plot(agent_id, exp.buffer_times, exp.recovery_times, False)"
   ],
   "id": "87598ac8e03ac315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timeout = 600\n",
    "pybooklogger.setLevel(logging.DEBUG)\n",
    "run_experiments(experiments, timeout)"
   ],
   "id": "80694dc9edcb08b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "### ATF Plot"
   ],
   "id": "651b83eda674b19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pybooklogger.setLevel(logging.WARNING)\n",
    "experiments[0].metadata = {'color': 'Red', 'label': 'No flexibility', 'offset': 5}\n",
    "experiments[1].metadata = {'color': 'Green', 'label': 'Buffer time', 'offset': 0}\n",
    "experiments[2].metadata = {'color': 'Blue', 'label': 'Recovery time', 'offset': -5}\n",
    "\n",
    "kwargs = {\"min_x\": 2700, \"max_x\": 3100, \"min_y\": 4250, \"max_y\": 5200, \"expected_arrival_time\": 4920}\n",
    "plot_experiments(experiments, **kwargs)\n",
    "\n",
    "\n",
    "experiments[0].metadata = {'color': 'Red', 'label': 'No flexibility', 'offset': 0}\n",
    "experiments[1].metadata = {'color': 'Green', 'label': 'Buffer time', 'offset': 0}\n",
    "experiments[2].metadata = {'color': 'Blue', 'label': 'Recovery time', 'offset': 0}\n",
    "\n",
    "plot_experiments([experiments[0]], **kwargs)\n",
    "plot_experiments([experiments[1]], **kwargs)\n",
    "plot_experiments([experiments[2]], **kwargs)"
   ],
   "id": "5bdf5a24d33937b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time statistics",
   "id": "c2c1a2b8a2846a9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sum_cols(df1, cols, name):\n",
    "    df2 = df1.drop(columns=cols)\n",
    "    df2[name] = df1[cols].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "time_df = pd.DataFrame([exp.get_running_time() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "setup_cols = [\"track graph creation\", \"routing graph creation\"]\n",
    "recompute_cols = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\"]\n",
    "search_cols = [\"FlexSIPP search time\"]\n",
    "\n",
    "time_df = sum_cols(time_df, setup_cols, \"Setup Time\")\n",
    "time_df = sum_cols(time_df, recompute_cols, \"Recompute Time\")\n",
    "time_df = sum_cols(time_df, search_cols, \"Search Time\")\n",
    "time_df"
   ],
   "id": "b6ad30666b929589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Node Statistics",
   "id": "822bacd6d5bfac85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nodes_df = pd.DataFrame([exp.get_complexity() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "nodes_df"
   ],
   "id": "f653f3c5c264dd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output paths found",
   "id": "fceb5b9d390137b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key, value in experiments[2].results[3].items():\n",
    "    delayed_trains = {i: v for i,v in enumerate(value[0][4]) if float(v[0]) > 0}\n",
    "    print(f\"{key.replace('r-', '')}\\nearliest departure: {int(min(float(value[0][1]), float(value[0][2])) / 60)}\\ndepart before: {int(float(value[0][2]) / 60)}\\narrive at: {int((float(value[0][1]) + float(value[0][3])) / 60)}\\ndelays trains: {delayed_trains}\")"
   ],
   "id": "b3e44210acfae8f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path statistics",
   "id": "db186086cd554870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    print(f\"Differend paths found for {exp.metadata['label']}: {sum(exp.results[2].values())}\")"
   ],
   "id": "559bc621b4f4c389",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiment Runtime\n",
    "Take a route of an agent with many stops, and run from start to every stop as an experiment\n"
   ],
   "id": "5f47ae0d2b66c332"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scenario_file = \"../data/prorail/scenarios/RT/2025-07-04_1.json\"\n",
    "\n",
    "try:\n",
    "    base_path = Path(__file__).parent\n",
    "    file_path = (base_path / scenario_file).resolve()\n",
    "    data = json.load(open(file_path))\n",
    "except:\n",
    "    data = json.load(open(scenario_file))\n",
    "types = {x[\"name\"]: x for x in data[\"types\"]}\n",
    "agents = []\n",
    "pybooklogger.setLevel(logging.CRITICAL)\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "for trainNumber, entry in enumerate(data[\"trains\"]):\n",
    "    trainNumber += 1\n",
    "    move = entry[\"movements\"][0]\n",
    "    velocity = types[entry[\"trainUnitTypes\"][0]][\"speed\"] / 3.6\n",
    "    block_path = layout.get_path_for_agent(move, trainNumber, velocity)\n",
    "\n",
    "    agent = Agent(trainNumber, move[\"startLocation\"], move[\"endLocation\"], velocity, move[\"startTime\"],\n",
    "                  endTime=move[\"endTime\"],\n",
    "                  startTimeHuman=str(timedelta(seconds=move[\"startTime\"])),\n",
    "                  endTimeHuman=str(timedelta(seconds=move[\"endTime\"])),\n",
    "                  blockPath=block_path,\n",
    "                  trainNumber=entry[\"trainNumber\"],\n",
    "                  trainUnitTypes=entry[\"trainUnitTypes\"],\n",
    "                  stops=move[\"stops\"]\n",
    "    )\n",
    "    agents.append(agent)\n",
    "\n",
    "agent_df = pd.DataFrame([agent.__dict__ for agent in agents])\n",
    "agent_df['blockPathLength'] = agent_df['blockPath'].map(len)\n",
    "\n",
    "print(f\"total blocks in path: {agent_df['blockPathLength'].sum()}\")\n",
    "print(f\"total edges in graph: {edges_df['Outgoing routes'].sum()}\")\n",
    "\n",
    "agent_df"
   ],
   "id": "77df2e906837522e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "longest = agent_df.loc[agent_df['stops'].map(len).idxmax()]\n",
    "\n",
    "# This train would be at 2700 at GV|6, we will be replanning its path till ASDZ|2\n",
    "longest\n"
   ],
   "id": "296f779094beddba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agent_id = longest['id']\n",
    "scenario = Scenario(layout, scenario_file, agent_id)"
   ],
   "id": "f3dd9b5fc7c98357",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment\n",
    "Define an experiment for every stop, and the original start and stop\n"
   ],
   "id": "7881db083e08b5c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = longest[\"start_time\"]\n",
    "origin = longest[\"origin\"]\n",
    "\n",
    "experiment_settings = [{\n",
    "        \"start_time\": start_time,\n",
    "        \"origin\": origin,\n",
    "        \"destination\": longest[\"destination\"],\n",
    "        \"metadata\": {\n",
    "            \"expected_arrival\": longest[\"endTime\"],\n",
    "            \"label\": f'route to {longest[\"destination\"]}'\n",
    "        }\n",
    "}]\n",
    "\n",
    "for stop in longest[\"stops\"]:\n",
    "    experiment_settings.append({\n",
    "        \"start_time\": start_time,\n",
    "        \"origin\": origin,\n",
    "        \"destination\": stop[\"location\"],\n",
    "        \"metadata\": {\n",
    "            \"expected_arrival\": stop[\"expected_arrival\"],\n",
    "            \"label\": f'route to {stop[\"location\"]}'\n",
    "        }\n",
    "    })\n",
    "\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "experiments = setup_experiment(scenario, experiment_settings)"
   ],
   "id": "ac516eaba18ad8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Blocking staircase diagram\n",
    "Showing the route of the agent with the most stops, its quite long.\n"
   ],
   "id": "e780778845d92f96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exp = experiments[0]\n",
    "exp.s.plot(agent_id, exp.buffer_times, exp.recovery_times, True)"
   ],
   "id": "39a3e09aa743b293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timeout = 600\n",
    "pybooklogger.setLevel(logging.DEBUG)\n",
    "run_experiments(experiments, timeout)"
   ],
   "id": "5808ee9f562d5ae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Results\n",
   "id": "dd74f1b44bf19df5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Time statistics",
   "id": "aab4774c8e2643e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sum_cols(df1, cols, name):\n",
    "    df2 = df1.drop(columns=cols)\n",
    "    df2[name] = df1[cols].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "time_df = pd.DataFrame([exp.get_running_time() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "setup_cols = [\"track graph creation\", \"routing graph creation\"]\n",
    "recompute_cols = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\"]\n",
    "search_cols = [\"FlexSIPP search time\"]\n",
    "\n",
    "time_df = sum_cols(time_df, setup_cols, \"Setup Time\")\n",
    "time_df = sum_cols(time_df, recompute_cols, \"Recompute Time\")\n",
    "time_df = sum_cols(time_df, search_cols, \"Search Time\")\n",
    "time_df"
   ],
   "id": "2ac6cd6227f736bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search Node Statistics\n",
   "id": "7dbae8073872c913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nodes_df = pd.DataFrame([exp.get_complexity() for exp in experiments], index=[exp.metadata['label'] for exp in experiments])\n",
    "\n",
    "nodes_df"
   ],
   "id": "7fddca82f590b30e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output paths found\n",
   "id": "957dd252e97c0d3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for key, value in experiments[2].results[3].items():\n",
    "    delayed_trains = {i: v for i,v in enumerate(value[0][4]) if float(v[0]) > 0}\n",
    "    print(f\"{key.replace('r-', '')}\\nearliest departure: {int(min(float(value[0][1]), float(value[0][2])) / 60)}\\ndepart before: {int(float(value[0][2]) / 60)}\\narrive at: {int((float(value[0][1]) + float(value[0][3])) / 60)}\\ndelays trains: {delayed_trains}\")"
   ],
   "id": "d393ad4e8ac3307c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Path statistics\n",
   "id": "eb39aeb16e0247bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for exp in experiments:\n",
    "    print(f\"Differend paths found for {exp.metadata['label']}: {sum(exp.results[2].values())}\")"
   ],
   "id": "fcc134b9431546c1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
