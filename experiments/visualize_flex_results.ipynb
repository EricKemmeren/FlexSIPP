{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ba763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2025-07-08_4\"\n",
    "filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", \"case_study_eurostar\", scenario, \"eurostar.csv\")\n",
    "df = pd.read_csv(filename)\n",
    "print(df.columns)\n",
    "trains = df['trainNumber'].unique()\n",
    "id_to_train_num = {}\n",
    "for id in df['id'].unique():\n",
    "    id_to_train_num[int(id)] = int(df[df['id'] == id]['trainNumber'].unique()[0])\n",
    "for t in trains:\n",
    "    df_train = df[df['trainNumber'] == t]\n",
    "    for i, ut in df_train.iterrows():\n",
    "        print(f\"Train {t} from {df_train['origin'].unique()[0]} at {df_train['start_time'].unique()[0]} to {df_train['destination'].unique()[0]} at {df_train['endTime'].unique()[0]} has {len(df_train)} entries, {i}th entry: delay at {ut['delay_location']} for {ut['delay_amount']} with ATF{ut['zeta'], ut['alpha'], ut['beta'], ut['delta']}\")\n",
    "        print(\"Path of Eurostar\", ut['path'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c32032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = {\n",
    "    \"Gv\": \"The Hague\",\n",
    "    \"Dt\": \"Delft\",\n",
    "    \"Dtcp\": \"Delft\",\n",
    "    \"Laa\": \"The Hague\",\n",
    "    \"Rtd\": \"Rotterdam\",\n",
    "    \"Shl\": \"Schiphol\",\n",
    "    \"Hfd\": \"Hoofddorp\",\n",
    "    \"Ledn\": \"Leiden\",\n",
    "    \"Sdm\": \"Schiedam\",\n",
    "    \"Rmoa\": \"Rotterdam\",\n",
    "    \"Gvm\": \"The Hague\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_delays = [180]\n",
    "\n",
    "def td_str(td):\n",
    "    return ':'.join(re.split(r'[:.]+', str(td)) [1:3])\n",
    "\n",
    "def extract_tipping_point(df):\n",
    "    def apply_func(df):\n",
    "\n",
    "        result=df.groupby(\"Location\").agg({\n",
    "            \"beta\": \"max\",\n",
    "            \"Delay Amount\": \"max\",\n",
    "        })\n",
    "        # result = result.loc[result['beta'] < 900]\n",
    "        # result[\"Tipping Point (sec)\"] = result[\"beta\"]\n",
    "        result[\"Tipping Point\"] = result[\"beta\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "\n",
    "        # def tp_finder(x):\n",
    "        #     new_tp = x['beta'] - max(0, x['Delay Amount'] - allowed_delay)\n",
    "        #     if new_tp > 0:\n",
    "        #         return td_str(timedelta(seconds=new_tp))\n",
    "        #     return \"-\"\n",
    "\n",
    "        # for allowed_delay in allowed_delays:\n",
    "        #     result[f\"Tipping Point ({allowed_delay}s)\"] = result.apply(tp_finder, axis=1)\n",
    "        # result[\"Delay Amount (sec)\"] = result[\"Delay Amount\"]\n",
    "        result[\"Delay Amount\"] = result[\"Delay Amount\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "        return result.sort_values(\"Tipping Point\", ascending=True).drop(columns=[\"beta\"])\n",
    "\n",
    "    df[\"Delay Location\"] = df[\"Delay Location\"].str.split(\"|\").apply(lambda x: x[0])\n",
    "    df[\"Location\"] = df[\"Delay Location\"].apply(lambda x: cities[x] if \"_\" not in x else cities[x.split(\"_\")[0]])\n",
    "    df = df.groupby(by='Train ID').apply(apply_func, include_groups=False)\n",
    "    return df\n",
    "\n",
    "tp_df = df.rename(columns={\n",
    "    \"delay_amount\": \"Delay Amount\",\n",
    "    \"delay_location\": \"Delay Location\",\n",
    "    \"trainNumber\": \"Train\",\n",
    "    \"id\": \"Train ID\",\n",
    "    \"scenario\": \"Scenario\",\n",
    "    \"label\": \"Label\",\n",
    "})\n",
    "tp_df[\"Scenario\"] = tp_df[\"Scenario\"].apply(lambda x: x.split(\".\")[0])\n",
    "tp_df[\"Delay Location\"] = tp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "tp_df = tp_df.groupby([\"Scenario\"]).apply(extract_tipping_point, include_groups=False)\n",
    "# tp_df = tp_df.rename(columns={\"Tipping Point\": \"Tipping Point (safe=beta)\"})\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tp_df.to_latex().split(\"\\n\")\n",
    "latex_filename = filename.replace(\"eurostar.csv\", \"table_tipping_points.tex\")\n",
    "new_lines = []\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    if \"\\begin{tabular}\" in lines[i]:\n",
    "        new_lines.append(r'\\begin{tabular}{llll}')\n",
    "    elif \"cline\" in lines[i]:\n",
    "        pass\n",
    "    elif lines[i] == r'\\toprule':\n",
    "        new_lines.append(r'\\toprule')\n",
    "        new_lines.append(r'Train & Location & Delay & Tipping point \\\\')\n",
    "        i += 2\n",
    "    elif lines[i][0:3] == r' & ':\n",
    "        # if \"multirow\" in lines[i]:\n",
    "        #     new_lines.append(r' & '.join([lines[i].split(r' & ')[1].split(\"{\")[-1].replace(\"}\", \"\")] + lines[i].split(r' & ')[2:]))\n",
    "        # else:\n",
    "        new_lines.append(r' & '.join(lines[i].split(r' & ')[1:]))\n",
    "    elif \"2025-07-08\" in lines[i]:\n",
    "        new_lines.append(r' & '.join(lines[i].split(r' & ')[1:]))\n",
    "    else:\n",
    "        new_lines.append(lines[i])\n",
    "    i += 1\n",
    "# for line in new_lines:\n",
    "#     print(line)\n",
    "with open(latex_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(new_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3549",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = df.groupby([\"scenario\", \"label\"])[\"path\"].count()\n",
    "\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe42839",
   "metadata": {},
   "source": [
    "# Runtime results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b62de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2025-07-08_4\"\n",
    "time_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", \"case_study_eurostar\", scenario, \"eurostar-time.csv\")\n",
    "time_df = pd.read_csv(time_filename)\n",
    "time_df = time_df.round(2).astype(str)\n",
    "pv = time_df.pivot_table(\n",
    "    columns=[\"scenario\", \"label\"],\n",
    "    values = [\"unsafe interval generation\", \"safe interval generation\", \"bt and crt generation\", \"converting routes to blocks\", \"track graph creation\", \"routing graph creation\", \"FlexSIPP search time\"]\n",
    ")\n",
    "pv.to_latex(time_filename.replace(\"eurostar-time.csv\", \"time_comparison.tex\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c862a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
