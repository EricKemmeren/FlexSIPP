{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ba763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7e668",
   "metadata": {},
   "source": [
    "# Get the tipping points for scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2025-07-08_4\"\n",
    "dir = \"case_study_eurostar\"\n",
    "filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, scenario, \"eurostar.csv\")\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c32032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = {\n",
    "    \"Gv\": \"The Hague\",\n",
    "    \"Dt\": \"Delft\",\n",
    "    \"Dtcp\": \"Delft\",\n",
    "    \"Laa\": \"The Hague\",\n",
    "    \"Rtd\": \"Rotterdam\",\n",
    "    \"Shl\": \"Schiphol\",\n",
    "    \"Hfd\": \"Hoofddorp\",\n",
    "    \"Ledn\": \"Leiden\",\n",
    "    \"Sdm\": \"Schiedam\",\n",
    "    \"Rmoa\": \"Rotterdam\",\n",
    "    \"Gvm\": \"The Hague\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_delays = [180]\n",
    "\n",
    "def td_str(td):\n",
    "    return ':'.join(re.split(r'[:.]+', str(td)) [1:3])\n",
    "\n",
    "def extract_tipping_point(df):\n",
    "    def apply_func(df):\n",
    "        result=df.groupby(\"Location\").agg({\n",
    "            \"beta\": \"max\",\n",
    "            \"Delay Amount\": \"max\",\n",
    "        })\n",
    "        result[\"Tipping Point\"] = result[\"beta\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "        result[\"Delay Amount\"] = result[\"Delay Amount\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "        return result.sort_values(\"Tipping Point\", ascending=True).drop(columns=[\"beta\"])\n",
    "    df[\"Delay Location\"] = df[\"Delay Location\"].apply(lambda x: x.split(\"|\")[0])\n",
    "    df[\"Location\"] = df[\"Delay Location\"].apply(lambda x: cities[x.split(\"_\")[0]] if x != \"\" else x)\n",
    "    df = df.groupby(by=['Train', 'Train ID']).apply(apply_func, include_groups=False)\n",
    "    return df\n",
    "\n",
    "tp_df = df.rename(columns={\n",
    "    \"delay_amount\": \"Delay Amount\",\n",
    "    \"delay_location\": \"Delay Location\",\n",
    "    \"trainNumber\": \"Train\",\n",
    "    \"id\": \"Train ID\",\n",
    "    \"scenario\": \"Scenario\",\n",
    "    \"label\": \"Label\",\n",
    "})\n",
    "tp_df[\"Scenario\"] = tp_df[\"Scenario\"].apply(lambda x: x.split(\".\")[0])\n",
    "tp_df[\"Delay Location\"] = tp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "# Only do one scenario\n",
    "tp_df = tp_df[tp_df[\"Scenario\"] == scenario]\n",
    "tp_df = extract_tipping_point(tp_df)\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tp_df.to_latex().split(\"\\n\")\n",
    "latex_filename = filename.replace(\"eurostar.csv\", \"table_tipping_points.tex\")\n",
    "new_lines = []\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    if \"\\begin{tabular}\" in lines[i]:\n",
    "        new_lines.append(r'\\begin{tabular}{llll}')\n",
    "    elif \"cline\" in lines[i]:\n",
    "        pass\n",
    "    elif lines[i] == r'\\toprule':\n",
    "        new_lines.append(r'\\toprule')\n",
    "        new_lines.append(r'Train & Location & Delay & Tipping point \\\\')\n",
    "        i += 2\n",
    "    elif r'&' in lines[i]:\n",
    "        # Remove first column which has train number\n",
    "        new_lines.append(r' & '.join(lines[i].split(r' & ')[1:]))\n",
    "    else:\n",
    "        new_lines.append(lines[i])\n",
    "    i += 1\n",
    "for line in new_lines:\n",
    "    print(line)\n",
    "with open(latex_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(new_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3549",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048220cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_trains_250708 = {\n",
    "    1: 64,\n",
    "    2: 82,\n",
    "    3: 77,\n",
    "    4: 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, \"eurostar_all.csv\")\n",
    "comp_df = pd.read_csv(all_filename)\n",
    "comp_df[\"Scenario\"] = comp_df[\"scenario\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0])).astype(int)\n",
    "comp_df[\"Trains\"] = comp_df[\"Scenario\"].apply(lambda x: number_trains_250708[x]).astype(int)\n",
    "comp_df[\"Location\"] = comp_df[\"delay_location\"].apply(lambda x: cities[x.split(\"|\")[0].split(\"-\")[1].split(\"_\")[0]] if x != \"-\" else x)\n",
    "comp_df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9593f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_delays = [180]\n",
    "\n",
    "def td_str(td):\n",
    "    return ':'.join(re.split(r'[:.]+', str(td)) [1:3])\n",
    "\n",
    "def extract_tipping_point(df):\n",
    "    def apply_func(df):\n",
    "        result=df.groupby(\"Delay Location\").agg({\n",
    "            \"alpha\": \"min\",\n",
    "            \"beta\": \"max\",\n",
    "            \"Delay Amount\": \"max\"\n",
    "        })\n",
    "        result = result.loc[result['alpha'] < 900]\n",
    "        result[\"Tipping Point\"] = result.apply(lambda x: td_str(timedelta(seconds=x['alpha'])) if x['alpha'] != x['beta'] else np.nan, axis=1)\n",
    "\n",
    "        def tp_finder(x):\n",
    "            new_tp = x['beta'] - max(0, x['Delay Amount'] - allowed_delay)\n",
    "            if new_tp > 0:\n",
    "                return td_str(timedelta(seconds=new_tp))\n",
    "            return \"-\"\n",
    "\n",
    "        for allowed_delay in allowed_delays:\n",
    "            result[f\"Tipping Point ({allowed_delay}s)\"] = result.apply(tp_finder, axis=1)\n",
    "        return result.sort_values(\"Tipping Point\", ascending=True).drop(columns=[\"alpha\", \"beta\"])\n",
    "    df[\"Delay Location\"] = df[\"Delay Location\"].str.split(\"|\").apply(lambda x: x[0])\n",
    "    df = df.groupby(by='Train ID').apply(apply_func, include_groups=False)\n",
    "    return df\n",
    "\n",
    "tp_df = comp_df.rename(columns={\n",
    "    \"delay_amount\": \"Delay Amount\",\n",
    "    \"delay_location\": \"Delay Location\",\n",
    "    \"id\": \"Train ID\",\n",
    "    \"label\": \"Label\",\n",
    "})\n",
    "tp_df = tp_df.groupby([\"Scenario\", \"Label\"]).apply(extract_tipping_point, include_groups=False)\n",
    "num_tps = tp_df.groupby([\"Scenario\", \"Label\"])[\"Tipping Point\"].count()\n",
    "num_tps = num_tps.unstack(\"Label\").astype(int)\n",
    "num_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = num_tps.to_latex().split(\"\\n\")\n",
    "num_filename = all_filename.replace(\"eurostar_all.csv\", \"table_comparison.tex\")\n",
    "new_lines_num = []\n",
    "i = 0\n",
    "while i < len(num_lines):\n",
    "    if num_lines[i] == r'\\toprule':\n",
    "        new_lines_num.append(r'\\toprule')\n",
    "        new_lines_num.append(num_lines[i+1].replace(r' & Label', r'Scenario & Trains'))\n",
    "        i += 2\n",
    "    elif \"cline\" in num_lines[i]:\n",
    "        pass\n",
    "    else:\n",
    "        new_lines_num.append(num_lines[i])\n",
    "    i += 1\n",
    "for line in new_lines_num:\n",
    "    print(line)\n",
    "with open(num_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(new_lines_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe42839",
   "metadata": {},
   "source": [
    "# Runtime results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_components = {\n",
    "    \"unsafe interval generation\": \"Conflict generation\",\n",
    "    \"safe interval generation\": \"Interval generation\",\n",
    "    \"bt and crt generation\": \"Flexibility generation\",\n",
    "    \"converting routes to blocks\": \"Block conversion\",\n",
    "    \"track graph creation\": \"Track graph creation\",\n",
    "    \"routing graph creation\": \"Routing graph creation\",\n",
    "}\n",
    "time_order = [\n",
    "    \"Track graph creation\",\n",
    "    \"Routing graph creation\",\n",
    "    \"Block conversion\",\n",
    "    \"Conflict generation\",\n",
    "    \"Interval generation\",\n",
    "    \"Flexibility generation\",\n",
    "    \"Search time FlexSIPP\",\n",
    "    \"Search time @MAEDeR\",\n",
    "    \"Search time rSIPP\"\n",
    "]\n",
    "algorithms_ordered = [\"FlexSIPP\", \"@MAEDeR\", \"rSIPP\"]\n",
    "column_order = [(s,a) for s in number_trains_250708.keys() for a in algorithms_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b62de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, \"eurostar-time_all.csv\")\n",
    "form = \"tex\"\n",
    "time_result = time_filename.replace(\"eurostar-time_all.csv\", f\"runtime_components.{form}\")\n",
    "time_df = pd.read_csv(time_filename)\n",
    "time_df[\"Scenario (num)\"] = time_df[\"scenario\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "time_df[\"Scenario\"] = time_df[\"scenario\"].apply(lambda x: f\"Scenario {x.split('_')[1].split('.')[0]}\")\n",
    "time_df[\"Search time FlexSIPP\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"FlexSIPP\" else np.nan, axis=1)\n",
    "time_df[\"Search time @MAEDeR\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"@MAEDeR\" else np.nan, axis=1)\n",
    "time_df[\"Search time rSIPP\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"rSIPP\" else np.nan, axis=1)\n",
    "for (old, new) in time_components.items():\n",
    "    time_df[new] = time_df[old]\n",
    "pv = time_df.pivot_table(\n",
    "    columns = [\"Scenario\"],\n",
    "    values = time_order,\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "pv = pv.loc[time_order]\n",
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lines = pv.to_latex(float_format=\"%.2f\").split(\"\\n\")\n",
    "print(time_lines)\n",
    "i = 0\n",
    "new_time_lines = []\n",
    "while i < len(time_lines):\n",
    "    if r'\\toprule' in time_lines[i]:\n",
    "        new_time_lines.append(time_lines[i])\n",
    "        new_time_lines.append(time_lines[i+1].replace(\"Scenario &\", \"Time Components &\"))\n",
    "        i += 1\n",
    "    else:\n",
    "        new_time_lines.append(time_lines[i])\n",
    "    i += 1\n",
    "for line in new_time_lines:\n",
    "    print(line)\n",
    "with open(time_result, \"w\") as f:\n",
    "    f.write('\\n'.join(new_time_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267736f1",
   "metadata": {},
   "source": [
    "# Old graphs for time components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = time_df.pivot_table(\n",
    "    columns = [\"Scenario (num)\", \"label\"],\n",
    "    values = time_order,\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "ax = pv.T.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(10,6)\n",
    "\n",
    ")\n",
    "min_font=12\n",
    "ax.set_xticklabels([x[1] for x in column_order], rotation=45, fontsize=min_font)\n",
    "column_names = [f\"Scenario {x}\" * len(time_df[\"label\"].unique()) for x in time_df[\"Scenario (num)\"].unique()]\n",
    "scen_name_pos = -0.2\n",
    "for i, col_name in enumerate(number_trains_250708.keys()):\n",
    "    ax.text(\n",
    "        i * len(time_df[\"label\"].unique()) + 1,\n",
    "        scen_name_pos,\n",
    "        f\"Scenario {col_name}\",\n",
    "        ha='center',\n",
    "        va='top',\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        fontsize=min_font\n",
    "    )\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(0.5,scen_name_pos*2), loc=\"center\", ncols=len(pv.index)/2, title=\"Time components\", title_fontsize=min_font, fontsize=min_font)\n",
    "plt.ylabel(\"Time in seconds\", fontsize=min_font)\n",
    "plt.yticks(fontsize=min_font)\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(time_result, format=form, dpi=600)\n",
    "plt.show()\n",
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8aca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_space = 1.2\n",
    "x = []\n",
    "group = 0\n",
    "for i, (col, typ) in enumerate(pv.columns):\n",
    "    pos_in_group = i % len(algorithms_ordered)\n",
    "    # base position + offset + spacing\n",
    "    x.append(group * (len(algorithms_ordered) + group_space) + pos_in_group)\n",
    "    # move to next group after every 2 bars\n",
    "    if pos_in_group == len(algorithms_ordered) - 1:\n",
    "        group += 1\n",
    "x = np.array(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "bottom = np.zeros(len(x))\n",
    "for row in time_order:\n",
    "    ax.bar(x, pv.loc[row], bottom=bottom, label=row)\n",
    "    bottom += pv.loc[row].values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(0.5,-0.3), loc=\"center\", ncols=len(pv.index)/2, title=\"Time components\")\n",
    "\n",
    "ax.set_xticklabels([x[1] for x in column_order], rotation=45)\n",
    "column_names = [f\"Scenario {x}\" * len(time_df[\"label\"].unique()) for x in time_df[\"Scenario\"].unique()]\n",
    "for i, col_name in enumerate(number_trains_250708.keys()):\n",
    "    ax.text(\n",
    "        i * len(time_df[\"label\"].unique()) + 1,\n",
    "        -0.15,\n",
    "        f\"Scenario {col_name}\",\n",
    "        ha='center',\n",
    "        va='top',\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "\n",
    "plt.ylabel(\"Time in seconds\")\n",
    "plt.xlabel(\"\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.savefig(time_result, format=form, dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
