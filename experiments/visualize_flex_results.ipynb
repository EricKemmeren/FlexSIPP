{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ba763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7e668",
   "metadata": {},
   "source": [
    "# Get the tipping points for scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2025-07-08_4\"\n",
    "dir = \"case_study_eurostar_pc\"\n",
    "filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, scenario, \"eurostar.csv\")\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c32032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = {\n",
    "    \"Gv\": \"The Hague\",\n",
    "    \"Dt\": \"Delft\",\n",
    "    \"Dtcp\": \"Delft\",\n",
    "    \"Laa\": \"The Hague\",\n",
    "    \"Rtd\": \"Rotterdam\",\n",
    "    \"Shl\": \"Schiphol\",\n",
    "    \"Hfd\": \"Hoofddorp\",\n",
    "    \"Ledn\": \"Leiden\",\n",
    "    \"Sdm\": \"Schiedam\",\n",
    "    \"Rmoa\": \"Rotterdam\",\n",
    "    \"Gvm\": \"The Hague\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_delays = [180]\n",
    "\n",
    "def td_str(td):\n",
    "    return ':'.join(re.split(r'[:.]+', str(td)) [1:3])\n",
    "\n",
    "def extract_tipping_point(df, show_column=\"Delay Location\"):\n",
    "    def apply_func(df):\n",
    "        result=df.groupby(show_column).agg({\n",
    "            \"beta\": \"max\",\n",
    "            \"Delay Amount\": \"max\",\n",
    "        })\n",
    "        result[\"Tipping Point\"] = result[\"beta\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "        result[\"Delay Amount\"] = result[\"Delay Amount\"].apply(lambda x: td_str(timedelta(seconds=x)))\n",
    "        return result.sort_values(\"Tipping Point\", ascending=True).drop(columns=[\"beta\"])\n",
    "    df[\"Delay Location\"] = df[\"Delay Location\"].apply(lambda x: x.split(\"|\")[0])\n",
    "    df[\"Location\"] = df[\"Delay Location\"].apply(lambda x: cities[x.split(\"_\")[0]] if x != \"\" and x != \"-\" else x)\n",
    "    df = df.groupby(by=['Train', 'Train ID']).apply(apply_func, include_groups=False)\n",
    "    return df\n",
    "\n",
    "tp_df = df.rename(columns={\n",
    "    \"delay_amount\": \"Delay Amount\",\n",
    "    \"delay_location\": \"Delay Location\",\n",
    "    \"trainNumber\": \"Train\",\n",
    "    \"id\": \"Train ID\",\n",
    "    \"scenario\": \"Scenario\",\n",
    "    \"label\": \"Label\",\n",
    "})\n",
    "tp_df[\"Scenario\"] = tp_df[\"Scenario\"].apply(lambda x: x.split(\".\")[0])\n",
    "tp_df[\"Delay Location\"] = tp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "# Only do one scenario\n",
    "tp_df = tp_df[tp_df[\"Scenario\"] == scenario]\n",
    "tp_df = extract_tipping_point(tp_df, \"Location\")\n",
    "tp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tp_df.to_latex().split(\"\\n\")\n",
    "latex_filename = filename.replace(\"eurostar.csv\", \"table_tipping_points.tex\")\n",
    "new_lines = []\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    if \"\\begin{tabular}\" in lines[i]:\n",
    "        new_lines.append(r'\\begin{tabular}{llll}')\n",
    "    elif \"cline\" in lines[i]:\n",
    "        pass\n",
    "    elif lines[i] == r'\\toprule':\n",
    "        new_lines.append(r'\\toprule')\n",
    "        new_lines.append(r'Train & Location & Delay & Tipping point \\\\')\n",
    "        i += 2\n",
    "    elif r'&' in lines[i]:\n",
    "        # Remove first column which has train number\n",
    "        new_lines.append(r' & '.join(lines[i].split(r' & ')[1:]).replace(\".000000\", \"\"))\n",
    "    else:\n",
    "        new_lines.append(lines[i])\n",
    "    i += 1\n",
    "for line in new_lines:\n",
    "    print(line)\n",
    "with open(latex_filename, \"w\") as f:\n",
    "    f.write(\"\\n\".join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c115f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = \"case_study_eurostar_pc\"\n",
    "# folder = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir)\n",
    "# filename_all = \"eurostar_all.csv\"\n",
    "# all_lines = []\n",
    "# for j, scenario in enumerate(os.listdir(folder)):\n",
    "#     filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, scenario, \"eurostar.csv\")\n",
    "#     if os.path.isfile(filename):\n",
    "#         tmp_df = pd.read_csv(filename)\n",
    "#         tmp_df = tmp_df.rename(columns={\"delay_amount\": \"Delay Amount\", \"delay_location\": \"Delay Location\",\"trainNumber\": \"Train\",\"id\": \"Train ID\",\"scenario\": \"Scenario\",\"label\": \"Label\",})\n",
    "#         tmp_df[\"Scenario\"] = tmp_df[\"Scenario\"].apply(lambda x: x.split(\".\")[0])\n",
    "#         tmp_df[\"Delay Location\"] = tmp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "#         tmp_df = tmp_df[tmp_df[\"Scenario\"] == scenario]\n",
    "#         tmp_df = extract_tipping_point(tmp_df, \"Location\")\n",
    "#         num_tps = tmp_df.groupby([\"Label\"])[\"Tipping Point\"].count()\n",
    "#         num_tps = num_tps.unstack(\"Label\").rename(\"\").astype(int)\n",
    "#         # lines = tmp_df.to_latex().split(\"\\n\")\n",
    "#         # i = 0\n",
    "#         # while i < len(lines):\n",
    "#         #     if \"\\begin{tabular}\" in lines[i]:\n",
    "#         #         if j == 0:\n",
    "#         #             all_lines.append(r'\\begin{tabular}{llll}')\n",
    "#         #     elif \"cline\" in lines[i]:\n",
    "#         #         pass\n",
    "#         #     elif lines[i] == r'\\toprule':\n",
    "#         #         if j == 0:\n",
    "#         #             all_lines.append(r'\\toprule')\n",
    "#         #             all_lines.append(r'Train & Location & Delay & Tipping point \\\\')\n",
    "#         #         i += 2\n",
    "#         #     elif r'&' in lines[i]:\n",
    "#         #         # Remove first column which has train number and print train id as int\n",
    "#         #         all_lines.append(r' & '.join(lines[i].split(r' & ')[1:]).replace(\".000000\", \"\"))\n",
    "#         #     elif (\"bottom\" in lines[i] or \"end\" in lines[i]) and j == 3:\n",
    "#         #         all_lines.append(lines[i])\n",
    "#         #     elif \"midrule\" in lines[i] and j == 0:\n",
    "#         #         all_lines.append(lines[i])\n",
    "#         #     else:\n",
    "#         #         print(\"check\", lines[i])\n",
    "#         #     i += 1\n",
    "# for line in all_lines:\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120ed49",
   "metadata": {},
   "source": [
    "# Tipping points VIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98200001",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2025-07-08_3\"\n",
    "\n",
    "virm_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, scenario, \"eurostar.csv\")\n",
    "# Input was 3500\n",
    "virm_df = pd.read_csv(virm_filename)\n",
    "vtp_df = virm_df.rename(columns={\n",
    "    \"delay_amount\": \"Delay Amount\",\n",
    "    \"delay_location\": \"Delay Location\",\n",
    "    \"trainNumber\": \"Train\",\n",
    "    \"id\": \"Train ID\",\n",
    "    \"scenario\": \"Scenario\",\n",
    "    \"label\": \"Label\",\n",
    "})\n",
    "vtp_df[\"Scenario\"] = vtp_df[\"Scenario\"].apply(lambda x: x.split(\".\")[0])\n",
    "vtp_df[\"Delay Location\"] = vtp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "# Only do one scenario\n",
    "vtp_df = vtp_df[vtp_df[\"Scenario\"] == scenario]\n",
    "vtp_df = extract_tipping_point(vtp_df, \"Delay Location\")\n",
    "vtp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3549",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c72aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir)\n",
    "filename_time = \"eurostar-time_all.csv\"\n",
    "all_time_df = []\n",
    "for scenario in os.listdir(folder):\n",
    "    if os.path.isdir(os.path.join(folder, scenario)):\n",
    "        all_time_df.append(pd.read_csv(os.path.join(folder, scenario, \"eurostar-time.csv\")))\n",
    "frame_time = pd.concat(all_time_df, axis=0, ignore_index=True)\n",
    "frame_time.to_csv(os.path.join(folder, filename_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048220cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_trains_250708 = {\n",
    "    1: 64,\n",
    "    2: 82,\n",
    "    3: 77,\n",
    "    4: 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, \"test_all.csv\")\n",
    "comp_df = pd.read_csv(all_filename, index_col=None)\n",
    "comp_df[\"Scenario\"] = comp_df[\"scenario\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0])).astype(int)\n",
    "comp_df[\"Trains\"] = comp_df[\"Scenario\"].apply(lambda x: number_trains_250708[x]).astype(int)\n",
    "comp_df[\"Location\"] = comp_df[\"delay_location\"].apply(lambda x: cities[x.split(\"|\")[0].split(\"-\")[1].split(\"_\")[0]] if x != \"-\" else x)\n",
    "res = comp_df.groupby([\"Scenario\", \"label\"])[\"path\"].count()\n",
    "res = res.unstack(\"label\").astype(int)\n",
    "lines = res[[\"FlexSIPP\", \"@MAEDeR\", \"rSIPP\"]].to_latex().split('\\n')\n",
    "i = 0\n",
    "new_lines = []\n",
    "while i < len(lines):\n",
    "    if \"toprule\" in lines[i]:\n",
    "        new_lines.append(lines[i])\n",
    "        new_lines.append(lines[i+1].replace(\"label\", \"Scenario\"))\n",
    "        i += 2\n",
    "    else:\n",
    "        new_lines.append(lines[i])\n",
    "    i += 1\n",
    "with open(all_filename.replace(\"test_all.csv\", \"table_comparison.tex\"), \"w\") as f:\n",
    "    f.write(\"\\n\".join(new_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9593f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowed_delays = [180]\n",
    "\n",
    "# def extract_tipping_point_all_scenarios(df):\n",
    "#     def apply_func(df):\n",
    "#         result=df.groupby(\"Delay Location\").agg({\n",
    "#             \"alpha\": \"min\",\n",
    "#             \"beta\": \"max\",\n",
    "#             \"Delay Amount\": \"max\"\n",
    "#         })\n",
    "#         result = result.loc[result['alpha'] < 900]\n",
    "#         result[\"Tipping Point\"] = result.apply(lambda x: td_str(timedelta(seconds=x['alpha'])) if x['alpha'] != x['beta'] else np.nan, axis=1)\n",
    "#         return result.sort_values(\"Tipping Point\", ascending=True).drop(columns=[\"alpha\", \"beta\"])\n",
    "#     df[\"Delay Location\"] = df[\"Delay Location\"].str.split(\"|\").apply(lambda x: x[0])\n",
    "#     df = df.groupby(by='Train ID').apply(apply_func, include_groups=False)\n",
    "#     return df\n",
    "\n",
    "# ctp_df = comp_df.rename(columns={\n",
    "#     \"delay_amount\": \"Delay Amount\",\n",
    "#     \"delay_location\": \"Delay Location\",\n",
    "#     \"id\": \"Train ID\",\n",
    "#     \"label\": \"Label\",\n",
    "# })\n",
    "# ctp_df = ctp_df.groupby([\"Scenario\", \"Label\"]).apply(extract_tipping_point_all_scenarios, include_groups=False).reset_index()\n",
    "# num_tps = ctp_df.groupby([\"Scenario\", \"Label\"])[\"Tipping Point\"].count()\n",
    "# num_tps = num_tps.unstack(\"Label\").rename(\"\").astype(int)\n",
    "# num_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_lines = num_tps.to_latex().split(\"\\n\")\n",
    "# num_filename = all_filename.replace(\"eurostar_all.csv\", \"table_comparison.tex\")\n",
    "# new_lines_num = []\n",
    "# i = 0\n",
    "# while i < len(num_lines):\n",
    "#     if num_lines[i] == r'\\toprule':\n",
    "#         new_lines_num.append(r'\\toprule')\n",
    "#         new_lines_num.append(num_lines[i+1].replace(r' & Label', r'Scenario & Trains'))\n",
    "#         i += 2\n",
    "#     elif \"cline\" in num_lines[i]:\n",
    "#         pass\n",
    "#     else:\n",
    "#         new_lines_num.append(num_lines[i])\n",
    "#     i += 1\n",
    "# for line in new_lines_num:\n",
    "#     print(line)\n",
    "# with open(num_filename, \"w\") as f:\n",
    "#     f.write(\"\\n\".join(new_lines_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dbf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir)\n",
    "# filename_all = \"eurostar_all_together.csv\"\n",
    "# all_lines = []\n",
    "# all_time_df = []\n",
    "# for scenario in os.listdir(folder):\n",
    "#     if os.path.isdir(os.path.join(folder, scenario)):\n",
    "#         tmp_df = pd.read_csv(os.path.join(folder, scenario, \"eurostar.csv\"))\n",
    "#         tmp_df = tmp_df.reset_index(drop=True)\n",
    "#         tmp_df[\"Scenario\"] = tmp_df[\"scenario\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0])).astype(int)\n",
    "#         tmp_df[\"Trains\"] = tmp_df[\"Scenario\"].apply(lambda x: number_trains_250708[x]).astype(int)\n",
    "#         tmp_df[\"Location\"] = tmp_df[\"delay_location\"].apply(lambda x: cities[x.split(\"|\")[0].split(\"-\")[1].split(\"_\")[0]] if x != \"-\" else x)\n",
    "#         # tmp_df[\"Location2\"] = tmp_df[\"delay_location\"].apply(lambda x: cities[x.split(\"_\")[0]] if x != \"\" and x != \"-\" else x)\n",
    "#         print(tmp_df[\"Location\"].unique())\n",
    "#         tmp_df = tmp_df.rename(columns={\n",
    "#             \"delay_amount\": \"Delay Amount\",\n",
    "#             \"delay_location\": \"Delay Location\",\n",
    "#             \"id\": \"Train ID\",\n",
    "#             \"trainNumber\": \"Train\",\n",
    "#             \"label\": \"Label\",\n",
    "#         })\n",
    "#         tmp_df[\"Delay Location\"] = tmp_df[\"Delay Location\"].apply(lambda x: x.split(\"-\")[1])\n",
    "#         tmp_df = tmp_df.groupby([\"Label\"]).apply(extract_tipping_point, include_groups=False).reset_index()\n",
    "# #         num_tps = ctp_df.groupby([\"Scenario\", \"Label\"])[\"Tipping Point\"].count()\n",
    "# #         num_tps = num_tps.unstack(\"Label\").rename(\"\").astype(int)\n",
    "# # num_tps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe42839",
   "metadata": {},
   "source": [
    "# Runtime results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_components = {\n",
    "    \"unsafe interval generation\": \"Conflict gen.\",\n",
    "    \"safe interval generation\": \"Interval gen.\",\n",
    "    \"bt and crt generation\": \"Flexibility gen.\",\n",
    "    \"converting routes to blocks\": \"Block conversion\",\n",
    "    \"track graph creation\": \"Track graph creation\",\n",
    "    \"routing graph creation\": \"Routing graph creation\",\n",
    "}\n",
    "time_order = [\n",
    "    r'Creation Routes~$\\network$',\n",
    "    \"Conflict gen.\",\n",
    "    \"Interval gen.\",\n",
    "    \"Flexibility gen.\",\n",
    "    \"Search FlexSIPP\",\n",
    "    \"Search @MAEDeR\",\n",
    "    \"Search rSIPP\"\n",
    "]\n",
    "algorithms_ordered = [\"FlexSIPP\", \"@MAEDeR\", \"rSIPP\"]\n",
    "column_order = [(s,a) for s in number_trains_250708.keys() for a in algorithms_ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b62de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filename = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"results\", dir, \"eurostar-time_all.csv\")\n",
    "form = \"tex\"\n",
    "time_result = time_filename.replace(\"eurostar-time_all.csv\", f\"runtime_components.{form}\")\n",
    "time_df = pd.read_csv(time_filename)\n",
    "time_df[r'Creation Routes~$\\network$'] = time_df.apply(lambda x: x[\"routing graph creation\"] + x[\"track graph creation\"] + x[\"converting routes to blocks\"], axis=1)\n",
    "time_df[\"Scenario (num)\"] = time_df[\"scenario\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0]))\n",
    "time_df[\"Scenario\"] = time_df[\"scenario\"].apply(lambda x: f\"Scen {x.split('_')[1].split('.')[0]}\")\n",
    "time_df[\"Search FlexSIPP\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"FlexSIPP\" else np.nan, axis=1)\n",
    "time_df[\"Search @MAEDeR\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"@MAEDeR\" else np.nan, axis=1)\n",
    "time_df[\"Search rSIPP\"] = time_df.apply(lambda x: x[\"FlexSIPP search time\"] if x[\"label\"] == \"rSIPP\" else np.nan, axis=1)\n",
    "for (old, new) in time_components.items():\n",
    "    time_df[new] = time_df[old]\n",
    "pv = time_df.pivot_table(\n",
    "    columns = [\"Scenario\"],\n",
    "    values = time_order,\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "pv = pv.loc[time_order]\n",
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lines = pv.to_latex(float_format=\"%.1f\").split(\"\\n\")\n",
    "print(time_lines)\n",
    "i = 0\n",
    "new_time_lines = []\n",
    "while i < len(time_lines):\n",
    "    if r'\\toprule' in time_lines[i]:\n",
    "        new_time_lines.append(time_lines[i])\n",
    "        new_time_lines.append(time_lines[i+1].replace(\"Scenario &\", \"Time Components &\"))\n",
    "        i += 1\n",
    "    else:\n",
    "        new_time_lines.append(time_lines[i])\n",
    "    i += 1\n",
    "for line in new_time_lines:\n",
    "    print(line)\n",
    "with open(time_result, \"w\") as f:\n",
    "    f.write('\\n'.join(new_time_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267736f1",
   "metadata": {},
   "source": [
    "# Old graphs for time components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = time_df.pivot_table(\n",
    "    columns = [\"Scenario (num)\", \"label\"],\n",
    "    values = time_order,\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")\n",
    "ax = pv.T.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(10,6)\n",
    "\n",
    ")\n",
    "min_font=12\n",
    "ax.set_xticklabels([x[1] for x in column_order], rotation=45, fontsize=min_font)\n",
    "column_names = [f\"Scenario {x}\" * len(time_df[\"label\"].unique()) for x in time_df[\"Scenario (num)\"].unique()]\n",
    "scen_name_pos = -0.2\n",
    "for i, col_name in enumerate(number_trains_250708.keys()):\n",
    "    ax.text(\n",
    "        i * len(time_df[\"label\"].unique()) + 1,\n",
    "        scen_name_pos,\n",
    "        f\"Scenario {col_name}\",\n",
    "        ha='center',\n",
    "        va='top',\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        fontsize=min_font\n",
    "    )\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(0.5,scen_name_pos*2), loc=\"center\", ncols=len(pv.index)/2, title=\"Time components\", title_fontsize=min_font, fontsize=min_font)\n",
    "plt.ylabel(\"Time in seconds\", fontsize=min_font)\n",
    "plt.yticks(fontsize=min_font)\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(time_result, format=form, dpi=600)\n",
    "plt.show()\n",
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8aca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_space = 1.2\n",
    "x = []\n",
    "group = 0\n",
    "for i, (col, typ) in enumerate(pv.columns):\n",
    "    pos_in_group = i % len(algorithms_ordered)\n",
    "    # base position + offset + spacing\n",
    "    x.append(group * (len(algorithms_ordered) + group_space) + pos_in_group)\n",
    "    # move to next group after every 2 bars\n",
    "    if pos_in_group == len(algorithms_ordered) - 1:\n",
    "        group += 1\n",
    "x = np.array(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "bottom = np.zeros(len(x))\n",
    "for row in time_order:\n",
    "    ax.bar(x, pv.loc[row], bottom=bottom, label=row)\n",
    "    bottom += pv.loc[row].values\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(0.5,-0.3), loc=\"center\", ncols=len(pv.index)/2, title=\"Time components\")\n",
    "\n",
    "ax.set_xticklabels([x[1] for x in column_order], rotation=45)\n",
    "column_names = [f\"Scenario {x}\" * len(time_df[\"label\"].unique()) for x in time_df[\"Scenario\"].unique()]\n",
    "for i, col_name in enumerate(number_trains_250708.keys()):\n",
    "    ax.text(\n",
    "        i * len(time_df[\"label\"].unique()) + 1,\n",
    "        -0.15,\n",
    "        f\"Scenario {col_name}\",\n",
    "        ha='center',\n",
    "        va='top',\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "\n",
    "plt.ylabel(\"Time in seconds\")\n",
    "plt.xlabel(\"\")\n",
    "plt.yscale(\"log\")\n",
    "# plt.savefig(time_result, format=form, dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
